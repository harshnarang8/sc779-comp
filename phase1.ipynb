{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPpPuAFv7NfUtkmpPXRx2PG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshnarang8/sc779-comp/blob/main/phase1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyuNBOVy64JJ"
      },
      "source": [
        "File for loading the code from github and syncing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilaOQl_zrCHn"
      },
      "source": [
        "from google.colab import drive\n",
        "from os.path import join\n",
        "\n",
        "ROOT = '/content/drive'\n",
        "PROJ = 'My Drive/'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k01XtgRC7yYb"
      },
      "source": [
        "# code to read the hinglish file\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekxJiv_xr6PB"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLO8ojGSTXNv"
      },
      "source": [
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJ3SDmfjNYRp",
        "outputId": "2de635be-f652-466a-8dd0-ff21c5bcb5bc"
      },
      "source": [
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDiOxXdkUGz4",
        "outputId": "03eb1602-2646-4129-84b2-56629274a632"
      },
      "source": [
        "drive.mount(ROOT)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lywTB-jxUa0i",
        "outputId": "71740061-5c78-4a9b-ec45-e4bbfb461c52"
      },
      "source": [
        "%cd 'Colab Notebooks'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Adt00u_l77Q7"
      },
      "source": [
        "train_file = pd.read_csv('AssignmentNLP/train/train.csv', index_col=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "l2XIdeII8u8i",
        "outputId": "feb0f387-73ee-4cbf-8462-831a526e4151"
      },
      "source": [
        "train_file.iloc[0, 0]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'एल सालवाडोर मे, जिन दोनो पक्षों ने सिविल-युद्ध से वापसी ली, उन्होंने वही काम किये जो कैदियों की कश्मकश के निदान हैं।'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTppM5tj94xr"
      },
      "source": [
        "# write a preprocessor, use a simple lstm, and get a bleu score result on training\n",
        "# let's just use word segmentation and pass it through an lstm for a basic mts.\n",
        "# need to use indic nlp lib, lets clone it here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qU4WrSpaTMcE",
        "outputId": "86acb1be-cbe0-46f1-e924-f7670687c99a"
      },
      "source": [
        "!git clone \"https://github.com/anoopkunchukuttan/indic_nlp_library\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'indic_nlp_library'...\n",
            "remote: Enumerating objects: 93, done.\u001b[K\n",
            "remote: Counting objects: 100% (93/93), done.\u001b[K\n",
            "remote: Compressing objects: 100% (68/68), done.\u001b[K\n",
            "remote: Total 1271 (delta 50), reused 54 (delta 25), pack-reused 1178\u001b[K\n",
            "Receiving objects: 100% (1271/1271), 9.56 MiB | 8.33 MiB/s, done.\n",
            "Resolving deltas: 100% (654/654), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRwYYT7JTV8a",
        "outputId": "2e04d8dd-9f61-43a6-d787-48375b85e7e4"
      },
      "source": [
        "!git clone https://github.com/anoopkunchukuttan/indic_nlp_resources.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'indic_nlp_resources'...\n",
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 133 (delta 0), reused 2 (delta 0), pack-reused 126\u001b[K\n",
            "Receiving objects: 100% (133/133), 149.77 MiB | 18.83 MiB/s, done.\n",
            "Resolving deltas: 100% (51/51), done.\n",
            "Checking out files: 100% (28/28), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-OWVpO1Tqua",
        "outputId": "6c0d1c8b-27a2-4107-a396-75c6e417825e"
      },
      "source": [
        "!pip install Morfessor"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Morfessor\n",
            "  Downloading https://files.pythonhosted.org/packages/39/e6/7afea30be2ee4d29ce9de0fa53acbb033163615f849515c0b1956ad074ee/Morfessor-2.0.6-py3-none-any.whl\n",
            "Installing collected packages: Morfessor\n",
            "Successfully installed Morfessor-2.0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYjq31eBT0xg"
      },
      "source": [
        "INDIC_NLP_LIB_HOME=\"indic_nlp_library\"\n",
        "INDIC_NLP_RESOURCES=\"indic_nlp_resources\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJ7GM9ISUpZq"
      },
      "source": [
        "import sys\n",
        "sys.path.append(r'{}'.format(INDIC_NLP_LIB_HOME))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mKB9bzsUtwY"
      },
      "source": [
        "from indicnlp import common\n",
        "common.set_resources_path(INDIC_NLP_RESOURCES)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pa2OrTAZUxhd"
      },
      "source": [
        "from indicnlp import loader\n",
        "loader.load()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7s1OH0r-VATc"
      },
      "source": [
        "from indicnlp.normalize.indic_normalize import BaseNormalizer\n",
        "from indicnlp.tokenize import indic_tokenize, indic_detokenize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJKEsqSmVMIe",
        "outputId": "0cf46d99-710b-492d-8469-4be1001a7e60"
      },
      "source": [
        "input_text = train_file.iloc[0,0]\n",
        "print(input_text)\n",
        "\n",
        "remove_nuktas=False\n",
        "normalizer = BaseNormalizer(\"hi\", remove_nuktas=False)\n",
        "output_text=normalizer.normalize(input_text)\n",
        "output_tokens = indic_tokenize.trivial_tokenize(input_text)\n",
        "output_tokens_2 = indic_detokenize.trivial_detokenize(input_text, lang=\"hi\")\n",
        "\n",
        "print(output_text)\n",
        "print(output_tokens)\n",
        "print(output_tokens_2)\n",
        "\n",
        "print('Before normalization')\n",
        "print(' '.join([ hex(ord(c)) for c in input_text ] ))\n",
        "print('Length: {}'.format(len(input_text)))\n",
        "print()    \n",
        "print('After normalization')\n",
        "print(' '.join([ hex(ord(c)) for c in output_text ] ))\n",
        "print('Length: {}'.format(len(output_text)))    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "एल सालवाडोर मे, जिन दोनो पक्षों ने सिविल-युद्ध से वापसी ली, उन्होंने वही काम किये जो कैदियों की कश्मकश के निदान हैं।\n",
            "एल सालवाडोर मे, जिन दोनो पक्षों ने सिविल-युद्ध से वापसी ली, उन्होंने वही काम किये जो कैदियों की कश्मकश के निदान हैं।\n",
            "['एल', 'सालवाडोर', 'मे', ',', 'जिन', 'दोनो', 'पक्षों', 'ने', 'सिविल', '-', 'युद्ध', 'से', 'वापसी', 'ली', ',', 'उन्होंने', 'वही', 'काम', 'किये', 'जो', 'कैदियों', 'की', 'कश्मकश', 'के', 'निदान', 'हैं', '।']\n",
            "एल सालवाडोर मे, जिन दोनो पक्षों ने सिविल-युद्ध से वापसी ली, उन्होंने वही काम किये जो कैदियों की कश्मकश के निदान हैं।\n",
            "Before normalization\n",
            "0x90f 0x932 0x20 0x938 0x93e 0x932 0x935 0x93e 0x921 0x94b 0x930 0x20 0x92e 0x947 0x2c 0x20 0x91c 0x93f 0x928 0x20 0x926 0x94b 0x928 0x94b 0x20 0x92a 0x915 0x94d 0x937 0x94b 0x902 0x20 0x928 0x947 0x20 0x938 0x93f 0x935 0x93f 0x932 0x2d 0x92f 0x941 0x926 0x94d 0x927 0x20 0x938 0x947 0x20 0x935 0x93e 0x92a 0x938 0x940 0x20 0x932 0x940 0x2c 0x20 0x909 0x928 0x94d 0x939 0x94b 0x902 0x928 0x947 0x20 0x935 0x939 0x940 0x20 0x915 0x93e 0x92e 0x20 0x915 0x93f 0x92f 0x947 0x20 0x91c 0x94b 0x20 0x915 0x948 0x926 0x93f 0x92f 0x94b 0x902 0x20 0x915 0x940 0x20 0x915 0x936 0x94d 0x92e 0x915 0x936 0x20 0x915 0x947 0x20 0x928 0x93f 0x926 0x93e 0x928 0x20 0x939 0x948 0x902 0x964\n",
            "Length: 116\n",
            "\n",
            "After normalization\n",
            "0x90f 0x932 0x20 0x938 0x93e 0x932 0x935 0x93e 0x921 0x94b 0x930 0x20 0x92e 0x947 0x2c 0x20 0x91c 0x93f 0x928 0x20 0x926 0x94b 0x928 0x94b 0x20 0x92a 0x915 0x94d 0x937 0x94b 0x902 0x20 0x928 0x947 0x20 0x938 0x93f 0x935 0x93f 0x932 0x2d 0x92f 0x941 0x926 0x94d 0x927 0x20 0x938 0x947 0x20 0x935 0x93e 0x92a 0x938 0x940 0x20 0x932 0x940 0x2c 0x20 0x909 0x928 0x94d 0x939 0x94b 0x902 0x928 0x947 0x20 0x935 0x939 0x940 0x20 0x915 0x93e 0x92e 0x20 0x915 0x93f 0x92f 0x947 0x20 0x91c 0x94b 0x20 0x915 0x948 0x926 0x93f 0x92f 0x94b 0x902 0x20 0x915 0x940 0x20 0x915 0x936 0x94d 0x92e 0x915 0x936 0x20 0x915 0x947 0x20 0x928 0x93f 0x926 0x93e 0x928 0x20 0x939 0x948 0x902 0x964\n",
            "Length: 116\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rmQSOi4crcQ"
      },
      "source": [
        "# class for building vocabulary, taken from the pytorch tutorial: https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n",
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "MAX_LENGTH = 300\n",
        "\n",
        "class lang:\n",
        "  def __init__(self, name):\n",
        "    self.name = name\n",
        "    self.word2idx = {}\n",
        "    self.word2count = {}\n",
        "    self.idx2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "    self.n_words = 2\n",
        "  \n",
        "  def addSent(self, sentence):\n",
        "    for word in indic_tokenize.trivial_tokenize(sentence):\n",
        "      self.addWord(word)\n",
        "  \n",
        "  def addWord(self, word):\n",
        "    if word not in self.word2idx:\n",
        "      self.word2idx[word] = self.n_words\n",
        "      self.word2count[word] = 1\n",
        "      self.idx2word[self.n_words] = word\n",
        "      self.n_words += 1\n",
        "    else:\n",
        "      self.word2count[word] += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9KuBCvkX2mx"
      },
      "source": [
        "def init_dataset(input_data):\n",
        "  pairs = []\n",
        "  hindi = lang('hi')\n",
        "  eng = lang('eng')\n",
        "  for i in range(len(input_data)):\n",
        "    hindi.addSent(input_data.iloc[i,0])\n",
        "    eng.addSent(input_data.iloc[i,1])\n",
        "    pairs.append((input_data.iloc[i,0], input_data.iloc[i, 1]))\n",
        "  print('Number of words:')\n",
        "  print(\"Hindi: \" + str(hindi.n_words))\n",
        "  print(\"English: \"+str(eng.n_words))\n",
        "  # init_dataset at this point has the pairs of sentences in a list\n",
        "  # we'd like to compute the vocabulary too, so let's see\n",
        "  return (pairs, hindi, eng)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IONQOLiWcnth",
        "outputId": "281f25f8-d7c3-4ddd-dc43-4f68067475cb"
      },
      "source": [
        "sent_pairs, hindi, eng = init_dataset(train_file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of words:\n",
            "Hindi: 46382\n",
            "English: 37706\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjN3_zx7SmqO"
      },
      "source": [
        "train_sent_pairs = sent_pairs[:80000]\n",
        "val_sent_pairs = sent_pairs[80000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYm2LO5Qo0z9"
      },
      "source": [
        "Now we have loaded the vocabularies and sent_pairs, we probably need to append the sos and eos tokens before actually using the pairs, lets figure out as we go."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxPsGD0AofvS"
      },
      "source": [
        "# for this version a simple encoder decoder framework, code is mostly retyped from the tutorial in the link already mentioned above\n",
        "class encoderRNN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size):\n",
        "    super(encoderRNN, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "\n",
        "    self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "    self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "  \n",
        "  def forward(self, input, hidden):\n",
        "    embedded = self.embedding(input).view(1, 1, -1)\n",
        "    output = embedded\n",
        "    output, hidden = self.gru(output, hidden)\n",
        "    return output, hidden\n",
        "  \n",
        "  def initHidden(self):\n",
        "    return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2O3FeQ6sNh_"
      },
      "source": [
        "class decoderRNN(nn.Module):\n",
        "  def __init__(self, hidden_size, output_size):\n",
        "    super(decoderRNN, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "\n",
        "    self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "    self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "    self.out = nn.Linear(hidden_size, output_size)\n",
        "    self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "  def forward(self, input, hidden):\n",
        "    output = self.embedding(input).view(1, 1, -1)\n",
        "    output = F.relu(output)\n",
        "    output, hidden = self.gru(output, hidden)\n",
        "    output = self.softmax(self.out(output[0]))\n",
        "    return output, hidden\n",
        "  \n",
        "  def initHidden(self):\n",
        "    return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06bxLG9oiSQS"
      },
      "source": [
        "Okay, we've written 2 things at this point, a language class which has a dictionary of words, and an encoder decoder model.\n",
        "Now, we need to create vectors for the sentences, write a few lines of code for the training routine.\n",
        "\n",
        "Let's do this before 1 am, 10:48 pm right now.\n",
        "\n",
        "Update: 2 am still no shit lol"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEcA9gpKtSyR"
      },
      "source": [
        "# replace inp and output lang \n",
        "input_lang = hindi\n",
        "output_lang = eng\n",
        "\n",
        "def indexesFromSentence(lang, sentence):\n",
        "  idxs = []\n",
        "  for word in indic_tokenize.trivial_tokenize(sentence):\n",
        "    if word in lang.word2idx:\n",
        "      idxs.append(lang.word2idx[word])\n",
        "  return idxs\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "  indexes = indexesFromSentence(lang, sentence)\n",
        "  indexes.append(EOS_token)\n",
        "  return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "  input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "  output_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "  return (input_tensor, output_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iqvLYStmieu"
      },
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "  encoder_hidden = encoder.initHidden()\n",
        "  \n",
        "  encoder_optimizer.zero_grad()\n",
        "  decoder_optimizer.zero_grad()\n",
        "\n",
        "  input_length = input_tensor.size(0)\n",
        "  target_length = target_tensor.size(0)\n",
        "\n",
        "  encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "  loss = 0\n",
        "\n",
        "  for ei in range(input_length):\n",
        "    encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
        "    encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "  decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "  decoder_hidden = encoder_hidden\n",
        "\n",
        "  use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "  if use_teacher_forcing:\n",
        "    for di in range(target_length):\n",
        "      decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "      loss += criterion(decoder_output, target_tensor[di])\n",
        "      decoder_input = target_tensor[di] # teacher forcing, since we feed target tensor to decoder\n",
        "  \n",
        "  else:\n",
        "    for di in range(target_length):\n",
        "      decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "      loss += criterion(decoder_output, target_tensor[di])\n",
        "      topv, topi = decoder_output.topk(1)\n",
        "      decoder_input = topi.squeeze().detach()\n",
        "\n",
        "      loss += criterion(decoder_output, target_tensor[di])\n",
        "\n",
        "      if decoder_input.item() == EOS_token:\n",
        "        break\n",
        "  \n",
        "  loss.backward()\n",
        "\n",
        "  encoder_optimizer.step()\n",
        "  decoder_optimizer.step()\n",
        "\n",
        "  return loss.item()/target_length\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FeGF_4vAA5W"
      },
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zURQKX9oBb0r"
      },
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(train_sent_pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFq9kN7jEWHC"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdhcPLCdEb4j"
      },
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.idx2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6aiSnwwEmj0"
      },
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(val_sent_pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GG4woRydEgZ0",
        "outputId": "e8f5c9e9-9a6f-4414-9a3e-27070b386332"
      },
      "source": [
        "hidden_size = 256\n",
        "encoder1 = encoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "decoder1 = decoderRNN(hidden_size, output_lang.n_words).to(device)\n",
        "\n",
        "trainIters(encoder1, decoder1, 100000, print_every=500)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0m 30s (- 100m 19s) (500 0%) 7.9384\n",
            "0m 48s (- 80m 2s) (1000 1%) 7.1847\n",
            "1m 7s (- 73m 37s) (1500 1%) 7.2538\n",
            "1m 25s (- 70m 11s) (2000 2%) 6.8070\n",
            "1m 45s (- 68m 31s) (2500 2%) 6.7720\n",
            "2m 3s (- 66m 38s) (3000 3%) 6.7627\n",
            "2m 23s (- 65m 49s) (3500 3%) 7.0020\n",
            "2m 43s (- 65m 15s) (4000 4%) 7.4187\n",
            "3m 2s (- 64m 38s) (4500 4%) 7.0162\n",
            "3m 23s (- 64m 17s) (5000 5%) 6.9590\n",
            "3m 44s (- 64m 19s) (5500 5%) 7.0130\n",
            "4m 6s (- 64m 24s) (6000 6%) 7.2552\n",
            "4m 27s (- 64m 2s) (6500 6%) 6.7576\n",
            "4m 47s (- 63m 43s) (7000 7%) 6.8668\n",
            "5m 8s (- 63m 28s) (7500 7%) 6.7842\n",
            "5m 29s (- 63m 9s) (8000 8%) 6.7867\n",
            "5m 50s (- 62m 53s) (8500 8%) 6.7884\n",
            "6m 12s (- 62m 45s) (9000 9%) 7.0533\n",
            "6m 32s (- 62m 20s) (9500 9%) 6.7575\n",
            "6m 54s (- 62m 9s) (10000 10%) 6.7609\n",
            "7m 15s (- 61m 55s) (10500 10%) 6.8595\n",
            "7m 36s (- 61m 32s) (11000 11%) 6.8725\n",
            "7m 57s (- 61m 12s) (11500 11%) 6.6953\n",
            "8m 17s (- 60m 50s) (12000 12%) 6.7488\n",
            "8m 39s (- 60m 36s) (12500 12%) 6.8000\n",
            "9m 0s (- 60m 17s) (13000 13%) 6.8098\n",
            "9m 21s (- 59m 59s) (13500 13%) 6.4894\n",
            "9m 43s (- 59m 44s) (14000 14%) 6.4820\n",
            "10m 4s (- 59m 27s) (14500 14%) 6.3623\n",
            "10m 26s (- 59m 9s) (15000 15%) 6.9257\n",
            "10m 47s (- 58m 51s) (15500 15%) 6.8120\n",
            "11m 9s (- 58m 34s) (16000 16%) 6.5929\n",
            "11m 31s (- 58m 16s) (16500 16%) 6.7963\n",
            "11m 52s (- 57m 59s) (17000 17%) 6.7896\n",
            "12m 14s (- 57m 43s) (17500 17%) 6.5441\n",
            "12m 35s (- 57m 20s) (18000 18%) 6.7008\n",
            "12m 56s (- 57m 2s) (18500 18%) 6.4263\n",
            "13m 17s (- 56m 38s) (19000 19%) 6.2119\n",
            "13m 38s (- 56m 19s) (19500 19%) 6.7398\n",
            "14m 0s (- 56m 2s) (20000 20%) 6.4490\n",
            "14m 22s (- 55m 44s) (20500 20%) 6.4499\n",
            "14m 42s (- 55m 21s) (21000 21%) 6.3771\n",
            "15m 4s (- 55m 2s) (21500 21%) 6.6036\n",
            "15m 26s (- 54m 44s) (22000 22%) 6.4787\n",
            "15m 48s (- 54m 26s) (22500 22%) 6.4250\n",
            "16m 9s (- 54m 5s) (23000 23%) 6.4771\n",
            "16m 31s (- 53m 46s) (23500 23%) 6.3491\n",
            "16m 52s (- 53m 26s) (24000 24%) 6.2400\n",
            "17m 13s (- 53m 6s) (24500 24%) 6.4974\n",
            "17m 35s (- 52m 47s) (25000 25%) 6.3678\n",
            "17m 56s (- 52m 25s) (25500 25%) 6.3410\n",
            "18m 18s (- 52m 5s) (26000 26%) 6.3956\n",
            "18m 39s (- 51m 44s) (26500 26%) 6.2388\n",
            "19m 1s (- 51m 25s) (27000 27%) 6.1833\n",
            "19m 23s (- 51m 6s) (27500 27%) 6.3458\n",
            "19m 45s (- 50m 48s) (28000 28%) 6.4625\n",
            "20m 7s (- 50m 28s) (28500 28%) 6.4166\n",
            "20m 28s (- 50m 7s) (29000 28%) 6.4928\n",
            "20m 50s (- 49m 48s) (29500 29%) 6.1135\n",
            "21m 11s (- 49m 27s) (30000 30%) 6.1910\n",
            "21m 33s (- 49m 7s) (30500 30%) 6.4413\n",
            "21m 55s (- 48m 48s) (31000 31%) 6.0085\n",
            "22m 17s (- 48m 27s) (31500 31%) 6.3281\n",
            "22m 39s (- 48m 9s) (32000 32%) 6.1887\n",
            "23m 1s (- 47m 48s) (32500 32%) 6.3662\n",
            "23m 22s (- 47m 28s) (33000 33%) 6.1483\n",
            "23m 45s (- 47m 10s) (33500 33%) 6.2321\n",
            "24m 6s (- 46m 48s) (34000 34%) 6.3520\n",
            "24m 28s (- 46m 28s) (34500 34%) 6.3181\n",
            "24m 51s (- 46m 9s) (35000 35%) 6.5572\n",
            "25m 12s (- 45m 48s) (35500 35%) 6.3142\n",
            "25m 35s (- 45m 29s) (36000 36%) 6.2970\n",
            "25m 55s (- 45m 6s) (36500 36%) 6.2745\n",
            "26m 17s (- 44m 46s) (37000 37%) 6.3215\n",
            "26m 39s (- 44m 25s) (37500 37%) 6.2477\n",
            "27m 0s (- 44m 4s) (38000 38%) 6.1440\n",
            "27m 22s (- 43m 43s) (38500 38%) 6.1848\n",
            "27m 42s (- 43m 20s) (39000 39%) 6.1372\n",
            "28m 5s (- 43m 1s) (39500 39%) 6.2758\n",
            "28m 28s (- 42m 43s) (40000 40%) 6.0544\n",
            "28m 49s (- 42m 21s) (40500 40%) 6.2887\n",
            "29m 11s (- 42m 0s) (41000 41%) 6.3301\n",
            "29m 33s (- 41m 39s) (41500 41%) 6.2457\n",
            "29m 54s (- 41m 18s) (42000 42%) 6.3300\n",
            "30m 16s (- 40m 57s) (42500 42%) 6.3162\n",
            "30m 39s (- 40m 37s) (43000 43%) 6.4541\n",
            "31m 1s (- 40m 17s) (43500 43%) 6.3974\n",
            "31m 22s (- 39m 55s) (44000 44%) 6.1668\n",
            "31m 43s (- 39m 33s) (44500 44%) 6.0707\n",
            "32m 3s (- 39m 11s) (45000 45%) 6.0977\n",
            "32m 25s (- 38m 50s) (45500 45%) 6.2853\n",
            "32m 46s (- 38m 28s) (46000 46%) 5.9964\n",
            "33m 7s (- 38m 6s) (46500 46%) 6.1190\n",
            "33m 28s (- 37m 45s) (47000 47%) 6.2371\n",
            "33m 51s (- 37m 24s) (47500 47%) 5.9567\n",
            "34m 12s (- 37m 3s) (48000 48%) 5.9378\n",
            "34m 34s (- 36m 42s) (48500 48%) 6.4037\n",
            "34m 56s (- 36m 21s) (49000 49%) 6.2568\n",
            "35m 19s (- 36m 1s) (49500 49%) 6.2634\n",
            "35m 40s (- 35m 40s) (50000 50%) 6.1259\n",
            "36m 1s (- 35m 18s) (50500 50%) 6.1934\n",
            "36m 22s (- 34m 57s) (51000 51%) 6.2700\n",
            "36m 44s (- 34m 36s) (51500 51%) 6.2061\n",
            "37m 6s (- 34m 15s) (52000 52%) 6.1847\n",
            "37m 27s (- 33m 53s) (52500 52%) 5.9220\n",
            "37m 49s (- 33m 32s) (53000 53%) 6.3793\n",
            "38m 10s (- 33m 10s) (53500 53%) 5.9951\n",
            "38m 31s (- 32m 49s) (54000 54%) 6.3423\n",
            "38m 55s (- 32m 29s) (54500 54%) 6.1408\n",
            "39m 17s (- 32m 8s) (55000 55%) 6.0259\n",
            "39m 38s (- 31m 47s) (55500 55%) 6.2193\n",
            "40m 0s (- 31m 26s) (56000 56%) 6.2303\n",
            "40m 22s (- 31m 4s) (56500 56%) 6.1674\n",
            "40m 43s (- 30m 43s) (57000 56%) 6.0925\n",
            "41m 3s (- 30m 21s) (57500 57%) 6.1031\n",
            "41m 25s (- 29m 59s) (58000 57%) 6.1378\n",
            "41m 46s (- 29m 38s) (58500 58%) 6.1626\n",
            "42m 7s (- 29m 16s) (59000 59%) 6.0130\n",
            "42m 29s (- 28m 55s) (59500 59%) 6.1887\n",
            "42m 51s (- 28m 34s) (60000 60%) 6.2297\n",
            "43m 12s (- 28m 12s) (60500 60%) 6.0831\n",
            "43m 34s (- 27m 51s) (61000 61%) 6.1549\n",
            "43m 56s (- 27m 30s) (61500 61%) 6.2387\n",
            "44m 17s (- 27m 8s) (62000 62%) 6.0589\n",
            "44m 38s (- 26m 46s) (62500 62%) 6.1743\n",
            "44m 59s (- 26m 25s) (63000 63%) 6.1428\n",
            "45m 20s (- 26m 3s) (63500 63%) 6.0337\n",
            "45m 42s (- 25m 42s) (64000 64%) 6.0208\n",
            "46m 4s (- 25m 21s) (64500 64%) 6.1027\n",
            "46m 26s (- 25m 0s) (65000 65%) 5.9852\n",
            "46m 48s (- 24m 39s) (65500 65%) 5.9853\n",
            "47m 9s (- 24m 17s) (66000 66%) 6.1855\n",
            "47m 30s (- 23m 56s) (66500 66%) 6.1731\n",
            "47m 52s (- 23m 34s) (67000 67%) 6.1143\n",
            "48m 15s (- 23m 13s) (67500 67%) 6.1240\n",
            "48m 36s (- 22m 52s) (68000 68%) 6.2114\n",
            "48m 58s (- 22m 31s) (68500 68%) 6.3497\n",
            "49m 20s (- 22m 10s) (69000 69%) 6.1902\n",
            "49m 42s (- 21m 48s) (69500 69%) 6.1970\n",
            "50m 3s (- 21m 27s) (70000 70%) 5.9754\n",
            "50m 24s (- 21m 5s) (70500 70%) 6.0325\n",
            "50m 46s (- 20m 44s) (71000 71%) 6.1087\n",
            "51m 7s (- 20m 22s) (71500 71%) 6.0615\n",
            "51m 27s (- 20m 0s) (72000 72%) 5.7861\n",
            "51m 51s (- 19m 40s) (72500 72%) 5.9701\n",
            "52m 13s (- 19m 19s) (73000 73%) 6.1067\n",
            "52m 35s (- 18m 57s) (73500 73%) 6.1350\n",
            "52m 55s (- 18m 35s) (74000 74%) 6.1561\n",
            "53m 15s (- 18m 13s) (74500 74%) 6.1310\n",
            "53m 36s (- 17m 52s) (75000 75%) 5.9158\n",
            "53m 57s (- 17m 30s) (75500 75%) 6.0196\n",
            "54m 19s (- 17m 9s) (76000 76%) 6.0420\n",
            "54m 42s (- 16m 48s) (76500 76%) 5.9132\n",
            "55m 1s (- 16m 26s) (77000 77%) 6.0469\n",
            "55m 23s (- 16m 4s) (77500 77%) 6.0673\n",
            "55m 45s (- 15m 43s) (78000 78%) 5.9747\n",
            "56m 6s (- 15m 22s) (78500 78%) 6.2557\n",
            "56m 28s (- 15m 0s) (79000 79%) 5.7897\n",
            "56m 49s (- 14m 39s) (79500 79%) 6.0789\n",
            "57m 10s (- 14m 17s) (80000 80%) 5.8860\n",
            "57m 31s (- 13m 56s) (80500 80%) 5.8143\n",
            "57m 52s (- 13m 34s) (81000 81%) 5.7665\n",
            "58m 14s (- 13m 13s) (81500 81%) 6.1434\n",
            "58m 36s (- 12m 51s) (82000 82%) 6.1338\n",
            "58m 57s (- 12m 30s) (82500 82%) 5.9695\n",
            "59m 18s (- 12m 8s) (83000 83%) 5.9672\n",
            "59m 39s (- 11m 47s) (83500 83%) 5.8113\n",
            "60m 1s (- 11m 25s) (84000 84%) 5.9290\n",
            "60m 22s (- 11m 4s) (84500 84%) 6.0267\n",
            "60m 42s (- 10m 42s) (85000 85%) 5.9119\n",
            "61m 4s (- 10m 21s) (85500 85%) 6.0801\n",
            "61m 27s (- 10m 0s) (86000 86%) 5.9414\n",
            "61m 49s (- 9m 38s) (86500 86%) 5.8923\n",
            "62m 10s (- 9m 17s) (87000 87%) 5.8505\n",
            "62m 31s (- 8m 55s) (87500 87%) 5.8363\n",
            "62m 53s (- 8m 34s) (88000 88%) 5.9043\n",
            "63m 15s (- 8m 13s) (88500 88%) 6.1031\n",
            "63m 37s (- 7m 51s) (89000 89%) 5.5945\n",
            "63m 58s (- 7m 30s) (89500 89%) 6.0665\n",
            "64m 19s (- 7m 8s) (90000 90%) 5.9642\n",
            "64m 40s (- 6m 47s) (90500 90%) 6.0192\n",
            "65m 1s (- 6m 25s) (91000 91%) 6.0751\n",
            "65m 22s (- 6m 4s) (91500 91%) 6.0601\n",
            "65m 44s (- 5m 43s) (92000 92%) 5.7648\n",
            "66m 6s (- 5m 21s) (92500 92%) 5.7958\n",
            "66m 28s (- 5m 0s) (93000 93%) 5.9155\n",
            "66m 50s (- 4m 38s) (93500 93%) 5.9281\n",
            "67m 13s (- 4m 17s) (94000 94%) 6.1254\n",
            "67m 34s (- 3m 55s) (94500 94%) 5.8609\n",
            "67m 55s (- 3m 34s) (95000 95%) 6.1387\n",
            "68m 16s (- 3m 13s) (95500 95%) 6.0805\n",
            "68m 38s (- 2m 51s) (96000 96%) 5.7623\n",
            "68m 59s (- 2m 30s) (96500 96%) 5.9146\n",
            "69m 20s (- 2m 8s) (97000 97%) 5.8374\n",
            "69m 41s (- 1m 47s) (97500 97%) 5.8319\n",
            "70m 2s (- 1m 25s) (98000 98%) 5.9020\n",
            "70m 24s (- 1m 4s) (98500 98%) 5.9541\n",
            "70m 46s (- 0m 42s) (99000 99%) 6.0900\n",
            "71m 8s (- 0m 21s) (99500 99%) 5.7659\n",
            "71m 28s (- 0m 0s) (100000 100%) 5.7674\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8lTSFPzU0Vp",
        "outputId": "3f1b649d-0f29-443a-dd92-6323ea8e2707"
      },
      "source": [
        "evaluateRandomly(encoder1, decoder1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> मेरा अच्छा बच्चा।\n",
            "= That's a good boy.\n",
            "< Good . . . . <EOS>\n",
            "\n",
            "> उसकानामएंटोनMarveltonहै\n",
            "= His name is Anton Marvelton.\n",
            "< It ' s <EOS>\n",
            "\n",
            "> जूलिया, एक बहुत 60 वर्षों में बदल ​​है.\n",
            "= Julia,a lot has changed in 60 years.\n",
            "< In , in the , . . <EOS>\n",
            "\n",
            "> तो बात तब की है, जब मेरी नई नई शादी हुई थी.\n",
            "= So what I did, I'd gone back to my early marriage days.\n",
            "< Then , when the the the the when was , of my the , <EOS>\n",
            "\n",
            "> गुड मॉर्निंग।\n",
            "= - Morning. What's that?\n",
            "< Good . . . <EOS>\n",
            "\n",
            "> तुम्‍हें किससे प्‍यार है?\n",
            "= Power. man: [laughs] woman:\n",
            "< What is s the ? <EOS>\n",
            "\n",
            "> तुम मुझे कहां ले लिया है?\n",
            "= Where have you taken me?\n",
            "< You me me me ? <EOS>\n",
            "\n",
            "> आई लव यू।\n",
            "= Thank God, Em. Daddy, I love you.\n",
            "< - . <EOS>\n",
            "\n",
            "> आप अध्यक्ष महोदय, तैयार हैं?\n",
            "= Are you ready, Mr. President?\n",
            "< You ' , to ' ? ? <EOS>\n",
            "\n",
            "> ऐसा क्यूँ होता है?\n",
            "= That brings us now to: why does this happen?\n",
            "< Why is it ? <EOS>\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaNe6LwniZtd"
      },
      "source": [
        "def evaluateSet(encoder, decoder, sentences, maxlength=MAX_LENGTH):\n",
        "  res = []\n",
        "  for sentence in sentences:\n",
        "    words = evaluate(encoder, decoder, sentence, maxlength)\n",
        "    res.append(' '.join(words[:-1]))\n",
        "  return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXwQKsvUrO96"
      },
      "source": [
        "hindi_csv = pd.read_csv('AssignmentNLP/hindiweek1/hindistatements.csv', index_col=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vX9ryxipsAho"
      },
      "source": [
        "hindi_set = []\n",
        "\n",
        "for sent in hindi_csv['hindi']:\n",
        "  hindi_set.append(sent)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRc3WZCSu4nQ"
      },
      "source": [
        "output_eng = evaluateSet(encoder1, decoder1, hindi_set, MAX_LENGTH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHrWFeMrw0-H"
      },
      "source": [
        "output_eng"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ByjKFOP0x5lu",
        "outputId": "ca9644ed-fd0d-4911-9915-1c738df29dbc"
      },
      "source": [
        "output_eng[-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'And the the the and of the'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBHxwDUbxCMY"
      },
      "source": [
        "with open('answers.txt', 'w') as file1:\n",
        "  for sent in output_eng[:-1]:\n",
        "    file1.write(sent)\n",
        "    file1.write('\\n')\n",
        "  file1.write(output_eng[-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "p09b-pwbgGS2",
        "outputId": "5f386136-1535-4bf6-bf6e-20b64c0cfb21"
      },
      "source": [
        "showPlot([1,2,3,4])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}